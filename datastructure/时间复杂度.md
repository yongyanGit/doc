### 时间复杂度

#### 大O复杂表示法

算法的执行效率，粗略地讲，就是算法代码执行的时间。

```java
 int cal(int n) {//1
   int sum = 0;//2
   int i = 1;//3
   for (; i <= n; ++i) {//4
     sum = sum + i;//5
   }//6
   return sum;//7
 }//8
```

从cpu的角度来看，这段代码的每一行都执行者类似的操作：读数据-运算-写数据。我们假设每一行的代码执行时间是一样的，为unit_time。然后在这个假设的基础上，再来看看这个段代码的总执行时间：

第2、3段代码分别需要1个unit_time的执行时间，第4、5行都运行了n遍，所以需要2n*unit_time的执行时间，所以这段代码的总的执行时间就是(2n+2)*unit_time。可以看出来，**所有代码的执行时间T(n)与每行代码的执行次数成正比**。

按照这个思路，再来分析下面的代码：

```java
 int cal(int n) {//1
   int sum = 0;//2
   int i = 1;//3
   int j = 1;//4
   for (; i <= n; ++i) {//5
     j = 1;//6
     for (; j <= n; ++j) {//7
       sum = sum +  i * j;//8
     }//9
   }//10
 }//11

```

如上：第2、3、4行代码，每行代码都需要1个unit_time的执行时间，第5、6代码循环执行了n遍，需要2n*unit_time的执行时间，第7、8行代码执行了2n遍，所以需要(2n^2+2n+3)*unit_time。

综上我们可以总结一个规律：**所有代码的执行时间T(n)与每行代码的执行次数n成正比**，即：

```
T(n) = O(f(n))
```

T(n)表示代码执行的时间；n表示数据规模的大小；f(n)表示每行代码执行的次数总和。公式中的O表示代码执行时间(T(n))与f(n)表达式成正比。

所以第一个例子中的T(n)=O(2n+2)，第二个例子中的T(n) = O(2n^2+2n+3)。这就是**大O时间复杂度表示法**。大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随着数据规模增长的变化趋势**，所以也叫做**渐进时间复杂度**，简称**时间复杂度**。

#### 时间复杂度分析

大O这种复杂度表示法只是表示一种变化趋势，我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。**我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了**。

```java
 int cal(int n) {//1
   int sum = 0;//2
   int i = 1;//3
   for (; i <= n; ++i) {//4
     sum = sum + i;//5
   }//6
   return sum;//7
 }//8
```

如上第2、3行代码都是常量级的执行时间，与n的大小无关，所以对于复杂度并没有什么影响。循环次数最多的是第4、5行代码，这两行代码被执行了n次，所以总的时间复杂度是O(n)。

再看如下的例子：

```java
public int cal(int n){

        int sum_1 = 0;
        int p = 1;
        for (; p < 100; ++p){
            sum_1 = sum_1 + p;
        }

        int sum_2 = 0;
        int q = 1;
        for (;q < n;++q){
            sum_2 = sum_2+q;
        }

        int sum_3 = 0;
        int i = 1;
        int j = 1;
        for (; i <= n;++i){
            j = 1;
            for (; j <= n;++i){
                sum_3 = sum_3 + i*j;
            }
        }
    
        return sum_1 + sum_2 + sum_3;
    }
```

如上代码分为三部分，分别是sum_1、sum_2、sum_3，我们可以分别分析每一段代码的时间复杂度，然后把它们放到一块，再取一个量级最大的作为整段代码的复杂度。

第一段代码循环执行了100次，所以是一个常量的执行时间，跟n的规模无关。时间复杂度它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉，因为它本身对增长趋势并没有影响。

第二段和第三段代码的时间复杂度分别是O(n)和O(n2)。综合这三段代码，我们取其中最大的量级，所以整段代码的时间复杂度为O(n2)。也就是说：**总的时间复杂度就等于量级最大的那段代码的时间复杂度**。

抽像成公式为:如果T1(n) = O(f(n)),T2(n)=O(g(n))，那么T(n)=T1(n)+T2(n)=max(O(f(n)),O(g(n)))=O(max(f(n),g(n)))。

```java
 public int cal2(int n){
        int ret = 0;
        int i = 1;
        for(; i < n;++i){
            ret = ret + f(i);
        }

        return ret;
    }

    int f(int n){
        
        int sum = 0;
        int i = 1;
        for (;i<n;++i){
            sum = sum + 1;
        }
        return sum;
    }
```

如上，cal2()函数，假设f()只是一个普通的操作，那么整个方法的复杂度就是T1(n) = O(n)。但是f()函数它本身的复杂度是T2(n)=O(n)，所以整个cal2()的函数复杂度就是T(n)=T1(n)*T2(n)=O(n2)。

#### 几种常见的时间复杂度

```
常量阶 O(1)
对数阶 O(logn)
线性阶 O(n)
线性对数阶 O(nlogn)
平方阶 O(n^2)、立方阶 O(n^3)...k次方阶O(n^k)
指数阶 O(2^n)
阶乘阶 O(n!)
```

1. O(1)

只要代码的执行时间不随着n的增大而增长，这样的代码的时间复杂我们都记作O(1)。或者说一般情况下，只要算法中不存在循环语句、递归。即使有成千上万行的代码，其时间复杂度也是O(1)。

```java
int i = 8;
int j = 6;
int sum = i+j;
```

2. O(logn)、O(nlogn)

```java
int i = 1;//1
while( i <= n){//2
    i = i*2;//3
}//4
```

如上代码，第三行是运行次数最多的代码，所以我们只要能计算出这行代码被执行了多少次，就知道整段代码的时间复杂度。

从代码中可以看出，变量i从1开始取，每循环一次就乘以2，当i大于n时，循环结束。

```
2^0 2^1 2^2...2^x = n
```

所以我们只要知道x的值就知道这行代码执行的次数了。通过2^x=n求解x可以得出：x=log2n(2是底数)，所以这段代码的的时间复杂度是：O(log2n)。

实际上，不管是以2为底、以3为底，还是以10为底，我们都可以把所有的对数阶的时间复杂度都记为O(logn)。

我们都知道对数之间可以相互转换的，log3n就等于log32*log2n，所以O(log3n)=O(C*log2n)，其中C=log32，基于前面一个理论：**在采用大O标记复杂度的时候，可以忽略系数，即O(Cf(n))=O(f(n))。所以O(log2n)就是等于O(log3n)。因此在对数阶时间复杂度的表示方法里，我们忽略对数的底，统一表示为O(logn)。

3. O(m+n)、O(m*n)

```java
public int cal3(int m,int n){

        int sum_1 = 0;

        int i = 1;
        for (;i<m;++i){
            sum_1 = sum_1 + 1;
        }

        int sum_2 = 0;
        int j = 1;
        for(;j<n;++j){
            sum_2 =sum_2 + 1;
        }
        return sum_1 + sum_2;
    }
```

从代码可以看出，m和n是表示数据规模，我们无法评估m和n谁的量级大，无法省略掉其中一个，所以上面的时间复杂度是O(m+n)即T1(m)+T2(n)=O(f(n)+f(m))。但是乘法法则依然有效：T1(m)*T2(n)=O(f(m)*f(n))。

![o](../images/datastructure/oo.jpg)

#### 最好、最坏情况时间复杂度

```
    public int find(int[] array,int n,int x){
        int i = 0;
        int pos = -1;
        for(;i<n;i++){
            if (array[i] == x) pos = i;
        }
        return pos;

    }

```

如上代码，从一个无序的数组中查询变量x的出现位置，如果找到就返回－1，按照前面的分析方法，它的复杂度是O(n)，其中n表示数组的长度。但是我们在一个数组中查找一个元素，并不是每次都把整个数组都遍历一遍，只要找到目标元素久可以结束循环了。

```java
public int find(int[] array,int n,int x){
        int i = 0;
        int pos = -1;
        for(;i<n;i++){
            if (array[i] == x) {
            	pos = i;
            	break;
            }
        }
        return pos;

    }
```

这个时候问题就来了，要查找的x可能出现在数组的任意位置，如果数组第一个元素正好是要查找的变量x，那么不需要继续遍历剩下的n-1个数据，那时间复杂度就是O(1)，如果数组中不存在变量，那我们就需要把整个数组都遍历一遍，时间复杂度就成了O(n)。

为了表示不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况复杂度。

**最好情况时间复杂度**就是在最理想的情况下执行这段代码，就像前面提到的正好要查找的变量x正好是数组的第一个元素；**最坏情况时间复杂度**就是在最糟糕的情况下，执行这段代码的时间复杂度，如前面我们需要遍历完整个数组才能查找到需要的元素x。

#### 平均时间复杂度

我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好的表示平均情况下的复杂度，我们需要引入另一个概念：平均情况复杂度。

我们要查找x在数组中的情况有n+1种，**在数组的0~n-1**位置中和**不在数组中**，即可以得到需要遍历的元素的平均值：

```
1+2+3+...n＋n/(n+1)=n(n+3)/2(n+1)
```

我们知道时间复杂度的大O标记法中，可以省略掉系数、低阶、常量，所以把刚刚这个公式简化之后，得到的平均时间复杂度就是O(n)。

虽然上面的结论正确，但是计算过程有点问题，我们没有将各种情况考虑进去。我们查找的变量X要么在数组中，要么就不在数组中。我们假设在数组与不在数组中的概率为1/2，另外要查找的数据出现在0~n-1这n个位置的概率也是一样的，为1/n。所以要查找的数据出现在0~n-1中任意位置的概率就是1/(2n)。

所以平均时间复杂度计算过程就变成了如下：

```
1*(1/2n)+2*(1/2n)+3*(1/2n)+...+n*(1/2n)+n*1/2=(3n+1)/4
```

这个值就是概率论中的加权平均值也叫做期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。（加权平均值即将各数值乘以相应的权数，然后加总求和得到总体值，再除以总的单位数）

引入概率之后，前面那段代码的加权平均值为(3n+1)/4。用大O表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是O(n)。

#### 均摊时间复杂度

```java
int[] array = new int[n];
    int count = 0;
    void insert(int val){
        if (count == array.length){
            int sum = 0;
            for(int i = 0;i<array.length;++i){
                sum = sum + array[i];
            }
            array[0] = sum;
            count = 1;
        }

        array[count] = val;
        ++count;
    }
```

如上代码，最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为count的位置就可以来，所以最好情况时间复杂度为O(1)。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为O(n)。

我们来看看它的平均时间复杂度是多少：

假设数组的长度是n，根据数据插入的位置不同，我们可以分为种情况，每种情况的时间复杂度是O(1)。除此之外，还有一种额外情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是O(n)。而且这n+1种情况发生的概率一样，都是1/(n+1)。所以根据加权平均的计算方法，我们求得的平均时间复杂度就是：

```
1*(1/n+1)+1*(1/n+1)...+1*(1/n+1)+n*(1/n+1)=O(1)
```

针对上面的例子还有更简单的算法：每一次O(n)的插入操作，都会跟着n-1次O(1)的插入操作，所以把耗时多的那次操作均摊到接下来的n-1次耗时少的操作，均摊下来，这一组连续的操作的均摊时间复杂度就是O(1)。

因此对于一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只要个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到那些时间复杂度低的操作上。