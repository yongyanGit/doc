### Kafka 可靠的数据传递

#### kafka一些机制

* Kafka可以保证分区消息的顺序，如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B。
* 只有当消息被写入分区的所有同步副本时（不一定写入磁盘），它才被认为是“已提交”的，生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。
* 只要还有一个副本是活跃的，那么已提交的消息就不会丢失。
* 消费者只能读取已经提交的消息。

#### 复制

Kafka的复制机制和分区的多副本架构是Kafka可靠性保证的核心。把消息写入多个副本可以使Kafka在发生崩溃时仍然保证消息的持久性。

Kafka的主题可以被分为多个分区，每个分区里的事件是有序的，每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其它副本只需要与首领保持同步，并且复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新的首领。

副本需要满足以下条件才能被认为是同步的：

* 与Zookeeper之间有一个活跃的会话，即在过去的6秒（可配置）内向Zookeeper发送过心跳。
* 在过去的10s内（可配置）从首领那里获取过消息。
* 在过去的10s内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还必须是几乎零延迟的。

如果同步副本不能满足以上的任何一点，比如：与Zookeeper断开连接，那么它就被认为是不同步的。一个不同步的副本通过与Zookeeper重新建立连接，并从首领那里获取最新的消息就可以重新变成同步的。

一个滞后的同步更少的同步副本，在发生宕机时丢失数据的风险更大。

#### broker 配置

1. 复制系数

主题级别的配置参数是replication.factor，而在broker级别则可以通过default.replication.factor来配置。

假如主题的复制系数是3，那么也就是每个分区总共会被3个不同的broker复制3次。如果复制系数是N，那么在N-1个broker失效的情况下，仍然能够从主题读取数据或向主题写入数据，但是更高的复制系统会带来更高的可用性、可靠性和更少的故障。另一方面复制系数N需要至少N个broker,而且会有N个数据副本，也就是说它们会占用N倍的磁盘空间。

2. 不完全的首领选举

当分区首领不可用时，一个同步副本会被选为新首领，如果选取过程中没有丢失数据，也就是说提交的数据同时存在于所有的同步副本上，那么这个选举就是完全的。但如果在首领不可用时其它副本都是不同步的，就是不完全的首领选举。它通过unclean.leader.election来进行配置，默认是true，即默认允许不同步的副本成为首领。

出现不完全的首领选举会在以下两种情景中出现：

* 假设某个分区有3个副本，其中两个副本broker发生崩溃，不可用了，这个时候如果生产者继续往首领写入数据，所有消息都会被得到确认并被提交（因为此时首领是唯一的同步副本），现在首领也不可用了，这个时候，如果之前的一个跟随者重新启动，它就成为了分区的唯一不同步的副本。
* 同样分区有三个副本，因为网络问题导致两个跟随者副本复制消息滞后，所以尽管它们还在复制消息，但是已经不同步了，首领作为唯一的同步副本继续接收消息，这个时候，如果首领变为不可用，另外两个副本就再也无法变成同步的了。

对于上面的场景，我们需要做出一个两难的选择：

* 如果不同步的副本不能被提升为新首领，那么分区的旧首领(最后一个同步副本)恢复之前是不可用的。有时候这种状态会持续数个小时。
* 如果不同步的副本可以被提升为首领，那么可能会造成数据丢失。假设副本0和副本1不可用时，偏移量100~200的消息被写入副本2（首领）。现在副本2变为不可用，副本0变为可用，副本0只包含偏移量0~100的消息，不包含偏移量100~200的消息。如果我们允许副本0成为新的首领，生产者就可以继续写入数据，消费者可以继续读取数据。于是，新首领就有了偏移量100~200的新消息，这样部分消费者就会读取到偏移量100~200的旧消息，部分消费者会读取到偏移量100~200的新消息，还有部分消费者会读取到二者的混合。另外副本2可能会重新变为可用，并成为新首领的跟随者，并把比首领旧的数据删除掉。

因此如果我们允许不同步的副本成为首领，那么就要承担丢失数据或者数据不一致的风险。如果我们不允许他们成为首领，那么就要接受较低的可用性，因为我们必须等待原先的首领恢复到可用状态。

3. 最少同步副本

通过参数min.insync.relicas来配置最少同步副本，对于一个包含3个副本的主题，如果将min.insync.relicas设置为2，那么至少要存在两个同步副本才能向分区写入数据。如果3个副本都是同步的，或者其中有一个副本变为不可用，都不会有什么问题，不过如果两个副本变为不可用，那么broker就会停止接收生产者的请求。尝试发送数据的生产者会收到NotEnoughReolicasExceprion的异常。但是消费者仍然可以继续读取已有的数据。

#### 在可靠的系统中使用生产者

即使把broker配置为很可靠，但是如果没有对生产者进行可靠性方面的配置，整个系统仍然可能会出现突发性的数据丢失。如下场景:

* 为分区配置了3个分区副本，并且禁用了不完全的首领选举。我们把生产者的发送消息的acks设为1(只要首领接受到消息就可以被认为消息写入成功)。生产者发送一个消息给首领，首领成功写入，但跟随着副本还没有接收到这个消息。首领向生产者发送一个“消息写入成功”的响应，然后它崩溃了，而此时消息还没有被其它副本复制过去。另外两个副本此时仍被认为是同步的，然后其中一个成为首领，因为消息还没有写入这个副本，所以消息丢失了，但是发送消息的客户端仍然认为消息写入成功了。
* 同样为分区分配了3个副本，并把生产者的acks设置为all。假设现在往Kafka发送消息，分区首领刚好崩溃了，新的首领正在选举当中，Kafka返回“首领不可用”的响应。在这个时候，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能丢失。

针对上面的场景，使用Kafka时需要注意两件事情：

* 根据可靠性需求配置恰当的acks值。
* 在参数配置和代码里正确处理错误

1. 发送确认

生产者可以选择以下三种不同的确认方式：

* acks=0 意味着生产者只要把消息通过网络发送出去，那么就认为消息成功写入了kafka。在这种情况下还是有可能会发生错误，如：对象无法被序列化、或者网络发生故障。但是如果分区离线或者整个集群长时间不可用，那就不会收到任何错误。即使是在完全首领选举的情况下，这种模式仍然会丢失消息，因为在新首领选举过程中它并不知道首领已经不可用了。
* acks= 1意味着首领在收到消息并把它写入分区数据文件时，会返回确认或者错误响应。在这个模式下，如果发生正常的首领选举，生产者会在选举时收到一个LeaderNotAvailableExceprion异常，如果生产者能恰当的处理这个异常，它会重新发送这个消息，最终消息会安全到达新的首领那里。不过这个模式下仍然可能会丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃。
* acks=all